{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4a3cc5-9277-416e-afef-aa9ab610baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skorch in c:\\users\\arist\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from skorch) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from skorch) (1.0.2)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from skorch) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from skorch) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arist\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arist\\anaconda3\\lib\\site-packages (from tqdm>=4.14.0->skorch) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# need to install skorch if you haven't done that\n",
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70828d57-9ba8-43cf-bccf-c33589c1c71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22681853b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Import packages \n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_openml # Import MNIST from a Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standard PyTorch Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# We will be using the PyTorch Wrapper Framework skorch to help simplify the coding\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# We need to import some Sci-kit Learn modules for computation purposes.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Global Settings - These settings are critical\n",
    "\n",
    "# If CUDA is available, use CUDA or else default to CPU.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Setting a seed for torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb864f6-c4c3-456a-813b-16189ffb6e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60000, 28, 28]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'X_train': <torch.utils.data.dataloader.DataLoader at 0x2268d3008b0>,\n",
       " 'y_train': <torch.utils.data.dataloader.DataLoader at 0x2268d300a90>,\n",
       " 'X_test': <torch.utils.data.dataloader.DataLoader at 0x2268d300df0>,\n",
       " 'y_test': <torch.utils.data.dataloader.DataLoader at 0x2268d300ee0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Import the data\n",
    "'''\n",
    "from torch.nn.functional import normalize\n",
    "# select the root = ....\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root = '/data', \n",
    "                                   train = True, \n",
    "                                   transform = transforms.ToTensor(),  \n",
    "                                   download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = '/data', \n",
    "                                          train = False, \n",
    "                                          transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "X_train = mnist.data\n",
    "y_train = mnist.targets\n",
    "\n",
    "X_test = test_dataset.data\n",
    "y_test = test_dataset.targets\n",
    "print(list(X_train.size()))\n",
    "\n",
    "'''\n",
    "Step -- Normalize each input from [0.0,1.0] range\n",
    "'''\n",
    "# print(X_train.float().mean(), X_train.float().std())\n",
    "X_train_norm = torch.nn.functional.normalize(X_train.float())\n",
    "X_test_norm = torch.nn.functional.normalize(X_test.float())\n",
    "\n",
    "print(X_train_norm.dim())\n",
    "\n",
    "\n",
    "'''\n",
    "Step -- Reshape X to have 4 dimension that is batch_size, channels, Height, Width\n",
    "'''\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'X_train' : torch.utils.data.DataLoader(X_train_norm, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    'y_train' : torch.utils.data.DataLoader(y_train, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'X_test'  : torch.utils.data.DataLoader(X_test_norm, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "           \n",
    "    'y_test'  : torch.utils.data.DataLoader(y_test, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8fe7bd-2299-4255-9d6e-47006c2556d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Will do some basic plotting to get a feel for the data that we imported.\n",
    "\n",
    "'''\n",
    "\n",
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y.item())\n",
    "        \n",
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3a9699-822e-49e4-99d3-c3bf54eda4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your CNN \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout = 0.4):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 5)\n",
    "        self.pool1 = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 5)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(512, 256)\n",
    "        self.drop1 = torch.nn.Dropout(dropout)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Step -- Fill in the Forward propagation function'''\n",
    "        \n",
    "        output = torch.relu(self.conv1(x))\n",
    "        output = self.pool1(output)\n",
    "        output = torch.relu(self.conv2(output))\n",
    "        output = self.pool2(output)\n",
    "        \n",
    "        output = output.reshape(-1, 512)\n",
    "        output = torch.relu(self.fc1(output))\n",
    "        output = self.drop1(output)\n",
    "        output = torch.relu(self.fc2(output))\n",
    "        output = self.drop2(output)\n",
    "        output = self.fc3(output)\n",
    "        \n",
    "        output = torch.Softmax(output)\n",
    "        \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ef3d5f-8e22-4537-986e-f8f441a9dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding L1 regularization\n",
    "\n",
    "class RegularizedNet(NeuralNetClassifier):\n",
    "    \n",
    "    ''''''\n",
    "    \n",
    "    def __init__(self, *args, lambda1 = 0.01, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lambda1 = lambda1\n",
    "    \n",
    "    ''' *** Explain -- What is the following method doing? Explain in detail in the main pdf ***'''\n",
    "    \n",
    "    def get_loss(self, y_pred, y_true, X = None, training = False):\n",
    "        loss = super().get_loss(y_pred, y_true, X = X, training = training)\n",
    "        loss += self.lambda1 * sum([w.abs().sum() for w in self.module_.parameters()])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018fef05-06cd-4c56-9d86-bd5414e011b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (drop1): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print out the structure of the model \n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30b4d96-3f31-4910-bc98-3eba015894a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we define the RegularizedNet. Make sure you use nn.NLLLoss. Thus, you have to use a correct last activation\n",
    "in the forward method of your network\n",
    "\n",
    "We can specify different parameters such as learning rate (lr), our optimizar (start with standard SGD, in 4.3 we will\n",
    "try another ones), batch size etc.\n",
    "To define the arquitecture parameters for CNN write them as module__ = ....\n",
    "\n",
    "Since we have to train it first with L2 regularization lambda1 should be equal to 0\n",
    "'''\n",
    "cnn = RegularizedNet(module = CNN, \n",
    "                     max_epochs = 10,\n",
    "                     criterion = torch.nn.NLLLoss, \n",
    "                     optimizer = torch.optim.SGD,\n",
    "                     lr = 0.1, \n",
    "                     lambda1 = 0,\n",
    "                     module__dropout = 0.4,\n",
    "                     optimizer__weight_decay = 0,\n",
    "                     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbd763c-b1e6-449c-95dd-35b7f269e034",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 5, 5], expected input[1, 128, 28, 28] to have 1 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''Step - train the network'''\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mLook how your loss is going down as well as the validation accuracy is increasing \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\classifier.py:141\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(NeuralNetClassifier, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1230\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1189\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1101\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_epoch_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_train, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1102\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1105\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1137\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[1;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_batch_begin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m=\u001b[39mbatch, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m-> 1137\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_fn(batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mrecord_batch(prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m   1139\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m (get_len(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[0;32m   1140\u001b[0m                   \u001b[38;5;28;01melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1016\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1011\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   1012\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   1013\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_accumulator\u001b[38;5;241m.\u001b[39mget_step()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:972\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[1;34m(self, step_fn)\u001b[0m\n\u001b[0;32m    970\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py:120\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 120\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    123\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1006\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m():\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_optimizer()\n\u001b[1;32m-> 1006\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step_single(batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1007\u001b[0m     step_accumulator\u001b[38;5;241m.\u001b[39mstore_step(step)\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1011\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   1012\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   1013\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:905\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    904\u001b[0m Xi, yi \u001b[38;5;241m=\u001b[39m unpack_data(batch)\n\u001b[1;32m--> 905\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(Xi, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    906\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss(y_pred, yi, X\u001b[38;5;241m=\u001b[39mXi, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    907\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skorch\\net.py:1427\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[1;34m(self, x, **fit_params)\u001b[0m\n\u001b[0;32m   1425\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx_dict)\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124;03m'''Step -- Fill in the Forward propagation function'''\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     20\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(output)\n\u001b[0;32m     21\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(output))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    441\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    442\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 5, 5], expected input[1, 128, 28, 28] to have 1 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "'''Step - train the network'''\n",
    "\n",
    "cnn.fit(X_train, y_train)\n",
    "y_pred_probs = cnn.predict(X_test)\n",
    "\n",
    "'''\n",
    "Look how your loss is going down as well as the validation accuracy is increasing \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00af1e3-1cff-4767-bcaa-9a2370b0b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step - Predict for the test set and print the final accuracy score, your validation accuracy obtained in the previous\n",
    "cell should be similar to the accuracy in the test set\n",
    "'''\n",
    "y_pred = cnn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
